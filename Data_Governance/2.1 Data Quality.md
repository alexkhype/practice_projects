## Importance of data quality

- **Data quality** is the degree to which data is fit for purpose, meeting standards of accuracy, completeness, consistency, validity, uniqueness, and timeliness. 
- High data quality means data closely represents the truth, enabling trust and reliable use in decision-making processes.  
- Increasing data quality enhances the value of data, leading to better business decisions and greater business value derived from data.

## Essential Data Quality Activities  

- Monitoring underlying data for quality and addressing issues promptly is crucial.  
- Data should be produced and consumed by those who understand its value.  
- Continuous execution of these activities maintains and increases both data value and business value.

## Value of Data Quality on the offense

- Companies with strong data quality processes gain a competitive edge by avoiding poor decisions based on bad data.  
- Managing customer data quality (e.g., removing duplicates) improves service, avoiding customer frustration and inefficiencies.

## Value of Data Quality on the defense

- Data quality helps identify and prevent risks and inefficiencies before they escalate, such as incorrect account balances that could cause financial loss.  
- Ensures business processes dependent on accurate data (like customer service) function smoothly without disruption from data errors.

## Data Quality Checks Before Use  
- Confirm data is the latest available, complete, without duplicates, and contains accurate and valid values.  
- Meeting these criteria increases confidence in data use, supporting reliable and effective decision-making.






## Data quality terms and concepts

## Defining Data Quality

- Data quality measures how well data serves its intended business purpose, focusing on whether data is accurate, valid, complete, and trustworthy. 
- High-quality data is essential for making informed business decisions and operating processes effectively. 
- Regular measurement and monitoring are necessary to maintain data quality, with business users setting **thresholds for acceptable data fitness**.

## Defining data quality dimensions

Data quality dimensions are specific attributes used to evaluate the quality of data. Key dimensions include:

- completeness
- validity
- uniqueness
- consistency
- timeliness
- accuracy

## Completeness as a dimension

Completeness can be assessed at the dataset or individual data element level. It measures whether all expected records are present and whether required data fields are populated. Missing data skews analysis and can lead to poor decisions. For example, a missing customer name in a record violates completeness rules.

## Validity as a dimension

Validity checks whether data values meet predefined business criteria. Validity is measured as the proportion of valid values, such as dates being in the past or values matching expected categories. Invalid entries, such as future birth dates or incorrect account types, indicate data quality issues.

## Uniqueness as a dimension

Uniqueness ensures there are no duplicate records in a dataset. Business context determines what constitutes a duplicate, often checked by unique identifiers like CustomerID. Duplicate full records or entries reduce data quality and violate uniqueness constraints.

## Timeliness as a dimension

- Timeliness measures how promptly a dataset is available when expected. It is tracked by comparing the actual data load time with the expected load time, typically defined by a service level agreement (SLA).
- For example, if data for the customer table is expected by 9:00 am but loads at 11:07 am, it fails the timeliness requirement.

## Consistency as a dimension

- Consistency measures how uniform data is across all instances, both across datasets and over time. It can be assessed by comparing data values between datasets or checking if record counts remain stable over time within acceptable limits (e.g., Â±5%).    
- For instance, a table loaded with approximately double the previous day's records is inconsistent. Another example includes ensuring Customer ID values match between two tables; mismatches are flagged as issues.
## Accuracy as a dimension

- Accuracy measures how correct data is, reflecting the truth and real-world facts. This dimension is challenging because it relies on having a reliable source of truth for comparison, which can be manual or automated.
- An example includes validating social security numbers by character length and verifying information like birth date and state against official tax form submissions.







## Roles and responsibilities involved in data quality activities

- Defining clear roles and responsibilities for data quality is a fundamental part of data governance.
- Roles are assigned by identifying everyone who produces, manages, or consumes data, even if these roles are not full-time.
- Responsibilities clarify what each role must accomplish in maintaining data quality.

## Data Producers

- Data producers are individuals who create, collect, process, transform, and store data.
- Examples include source system owners, database owners, ETL developers, report writers, and data scientists.
- Producers implement technical data quality rules, set up alerts, correct issues, and define technical data quality rules.

## Data Consumers

- Data consumers consume or use data from an upstream data for various purposes, such as reporting or analysis.
- Examples include report writers, data scientists, and ETL developers.
- They provide feedback on business-related data quality rules and assess data quality before use.    
- Consumers report quality issues back to producers and decide the risk level acceptable for poor-quality data.

## Dual Role: Producer and Consumer

- Some roles, like ETL developers, data scientists, and report writers, both consume upstream data and produce derived data.    
- Responsibilities depend on whether quality issues arise in the original source data or in transformed/derived data.

## Data Governance Team

- Oversees the entire data quality program and governance. A data governance team may be comprised of data governance, data quality, and metadata resources.
- Responsible for defining and enforcing data quality policies, roles, and standards.
- Monitors data quality dashboards and ensures tools, processes, and training are in place.
